# SIG-Testing meeting notes from 2021-07-01 @ 1800 UTC

# Housekeeping
Agenda is at https://github.com/o3de/sig-testing/issues/2

Have chatbot start recording session in discord with
!record

Any volunteers for taking notes? Comfortable to both facilitate and take notes

### SIG Updates
There are no updates since the previous meeting, as this is the first meeting!  We are currently trying to bootstrap this SIG, to prepare it for success when it is handed off to the Linux Foundation. The current meeting participants are expected to be the majority of the members of this public SIG through launch.

** Introductions

Sean Sweeney - Sr. Developer in Test on internal Test Tools team
Chris Morocho - QA Engineer on Platforms team
Fuzzy - QA Engineer Asset pipeline
Scott Murray - QA Engineer been on project since the early days
Danilo Amini - Engineer on the Foundation team, previously worked on Hydra Editor Python Bindings system
David Kerwin - QA Manager at Amazon
Andrew Jackson - QA Engineer on Foundation team, editor and world building tools
Evgueni Netchaev - Sr. QA Manager
Evan Chiang - Developer in Test
Rob Cook - QA Engineer
Kriti Nagam - QA Engineer

** SIG Charter Review
Reviewing document at: https://github.com/o3de/sig-testing/pull/1/files

Ensure that standard of testing is the same across SIGs as a goal

Mentioned in overview and in scope - metrics, explicitly include as part of first bullet point

In-scope mentions metrics and Code Coverage - goal for this SIG to put forward, setting thresholds for e.g. metrics values - Testing SIG to define recommended goals and approach for code coverage?

Should not enforce or police other SIG's goals, we should provide the tools and metrics that enable them to work efficiently

Have things for e.g. escaped bug rate, to track and see this data before it is actionable

Set a standard around issue tracking, bug reports - issue reporting guidelines, maintain recommended template

Performance testing - add to goals, make more prominent in other sections

Do we want to add a section in-scope to suggest "enabling others to pursue platform testing" - mentioned in Goals, mention this as in-scope. Educate and support others doing this themselves, similar to line 50 - specifically call out supporting platforms

Perhaps need platform support in AR pipeline goal?

Advise automation creators about maintaining platform-agnostic automation code

"Testing Software" is ambiguous: act of testing software, and software used for testing

Added a comment - documentation section, should have guidelines on how to engage with Testing SIG. What someone should bring to the table to start a discussion without thrash.  Documentation around GH issues: bug database process, templates, etc.

Include bug/issue lifecycle in goals

Is the testing SIG providing SLAs about bugs, blockers, and AR? SLA around fixing blocker bug, if SIG breaks the build need to fix. Questionable around breaking tests vs builds.Should testing SIG be actively enforcing the SLA? Should propose what the SLA should be, and get that accepted by the other SIGs. Can report on this, but should not own all action. If there is a serial violator of the policies, should be on the board and SIG chairs to resolve problems. Move into crosscutting processes.

Question on minimum performance requirements - seems to be a huge task. We should not be setting what these targets are. We should enable each SIG to track their performance targets. Can move to out of scope, since we are not defining performance targets. If we keep this point, it should be specific to test automation.

Concern with cross-cutting term. Does not seem to be standard terminology outside of Amazon. Can discuss with Royal, perhaps should be called out in sig-governance. Could be defined directly here, that this Cross-cutting section is for what other SIGs need answers for.

Bullet point on Releases seems to be a bit vague.  Will work with Release-SIG when a given release is being cut.  Likely will not be a singular quality bar on every release.

Out of scope section

Include writing and executing automated tests in line 73... sub bullet of line 68

Dashboard system as out of scope - currently owned by MARS team outside of quality. Any metrics and data gathering will likely be internal only. Since this is open source, Amazon no longer owns it, and we should not gather metrics from external partners. O3DE documentation and dashboards should be available to everyone. Anything that pulls data and stores it privately is likely not going to happen. There is additional work around this for releasing metrics software, which is getting into information security questions. Tabled discussion.

Clarify role of contributors based on sig-governance, have a short definition in this doc

Requirements of being an active maintainer. Do we want to specify test code for the bullet on line 107? Github primarily views PRs, comments on PRs, and issue creation as activity.

Line 110 what is a team? This SIG? Line seems more chair-like with organizing meetings. Move to chair. Clarify to: If a meeting needs to be held, and you are not a maintainer, contact a maintainer to help arrange that. Maintainers should identify when meetings need to be held. Could have a similar bullet to line 111 about raising agendas - could add "when appropriate" and clarify around meeting with other SIGs vs meetings within this SIG.


## Wrap up

Charter needs another revision and another review before ratification.

Chatbot should provide a URL to an mp3 when you stop recording the session with:
!stop-recording

Please use audio editing software to remove pauses longer than 10 seconds and normalize the audio, and then zip the audio file before uploading to github.

Also update sig-testing/meetings/readme.md with date and summary information